# Copilot / AI contributor notes — quordle-scores

This repository is a small Python project that collects Quordle results from sent emails, stores them in a local SQLite DB, exports CSV for a static dashboard, and contains a static `docs/` visualization.

Key files and roles
- `email-reader-with-sqlite.py` — reads Sent emails (IMAP), parses emoji/score text, and writes rows into `quordle_scores` SQLite table. Uses env vars `IMAP_SERVER`, `EMAIL_USERNAME`, `EMAIL_PASSWORD` when available; otherwise prompts interactively.
- `extract_to_csv.py` — exports rows from SQLite into a CSV with header: `Date,Score 1,Score 2,Score 3,Score 4,Sum,Max`. Called with `python extract_to_csv.py <db> <out.csv>`.
- `insert_from_csv.py` — imports `import.csv` into `quordle_scores.db` if rows are not already present. The script uses a default filename and a default DB path in code.
- `docs/index.html` — static dashboard that expects a CSV at `/quordle-data/quordle_scores.csv` and performs client-side parsing + Chart.js rendering.
- `quordle-data/quordle_scores.csv` — canonical CSV used by the dashboard (generated by `extract_to_csv.py`).
- `requirements.txt` — minimal Python deps (project uses `emoji` lib). A `env/` virtualenv is present in repo but developers normally create their own venv.

Big-picture architecture & data flow
- Data source: Quordle result emails in the Sent folder. `email-reader-with-sqlite.py` parses these, converting emoji red squares to a `13` fail marker and numeric emoji characters to numeric scores.
- Persistence: a local SQLite DB (`quordle_scores.db`) with table `quordle_scores` (fields: `email_date`, `parsed_date`, `score1..score4`, `raw_email`, `date_added`).
- Export: `extract_to_csv.py` reads SQLite and produces `quordle_scores.csv` used by the static site in `docs/` or by `quordle-data/`.
- Presentation: `docs/index.html` loads the CSV client-side (via PapaParse) and renders charts with Chart.js.

Developer workflows (how to run common tasks)
- Create a venv and install deps:
  ```powershell
  python -m venv .venv; .\.venv\Scripts\Activate.ps1; pip install -r requirements.txt
  ```
- Pull scores from your Sent emails (interactive or via env vars):
  ```powershell
  python email-reader-with-sqlite.py quordle_scores.db
  # or set IMAP_SERVER, EMAIL_USERNAME, EMAIL_PASSWORD env vars to run non-interactively
  ```
- Export CSV used by the static dashboard:
  ```powershell
  python extract_to_csv.py quordle_scores.db quordle-data\quordle_scores.csv
  ```
- Import CSV into DB (script defaults to `import.csv` and `quordle_scores.db`):
  ```powershell
  # ensure import.csv exists at repo root or adjust script
  python insert_from_csv.py
  ```
- Preview the dashboard locally: serve the repository root so `docs/` and `quordle-data/` are accessible at the same server root. Example:
  ```powershell
  # from repo root
  python -m http.server 8000
  # open http://localhost:8000/docs/index.html
  ```

Project-specific conventions & gotchas
- Score encoding: A red square emoji in emails is translated to `13` (fail). Code in `email-reader-with-sqlite.py:parseSnippet` finds numeric characters in the emoji snippet or maps `:red_square:` → 13.
- CSV quirks: `docs/index.html` filters out rows with `Sum === 52` (treated as missed days) and computes `Sum`/`Max` when missing. When generating CSV prefer including `Sum` and `Max` but `extract_to_csv.py` computes them itself.
- Script arguments: `extract_to_csv.py` uses argparse and needs `<db> <out.csv>`. `insert_from_csv.py` is less flexible (defaults to `import.csv`) — update it if you need a different input filename.
- IMAP Sent-folder selection is heuristic and may not find all mail providers; the script tries an Inbox-based selection and then a simple search. Expect manual troubleshooting for nonstandard providers.

Integration points & externals
- External libs: `emoji` (see `requirements.txt`). The static dashboard uses CDN-hosted PapaParse, Chart.js and date-fns.
- No external API keys are stored here. Email credentials should be provided by environment variables for automation.

Examples to copy when changing code
- When adding a new extraction step, follow `extract_to_csv.py` style: small CLI, clear errors, return human-readable messages.
- When modifying DB schema, update both `email-reader-with-sqlite.py` CREATE TABLE DDL and `extract_to_csv.py` queries.

What not to change lightly
- `parseSnippet` behaviour and the `13` fail mapping — changing it will break historical CSV semantics and the dashboard's filters.
- The CSV header expected by `docs/index.html` (`Date,Score 1,...,Max`) — keep that stable or update the dashboard concurrently.

If you need more
- Ask for specific examples to add (unit tests, CI, or scripts to parameterize `insert_from_csv.py`).

Please review and tell me which areas you want expanded (examples for tests, CI commands, or more exact HTTP-serving instructions on Windows).
